Po aferze z udziałem Cambridge Analytica stało się jasne, że apolityczność mediów społecznościowych i innych cyfrowych gigantów to fikcja. Nauczkę ze skandalu próbuje wynieść Unia Europejska, ale jak na razie jedynie ostrzegawczo grozi Markowi Zuckerbergowi palcem. Lekcję odrobiły z kolei partie polityczne, które wiedzą, że prawdziwa gra o władzę toczy się w sieci. A jak jest w Polsce?

To pytanie zadali sobie przedstawiciele Fundacji Panoptykon, Fundacji ePaństwo oraz firmy SmartNet Research & Solutions, inicjatorzy projektu badawczego Mikrotargetowanie polityczne w Polsce pod lupą: oparta na dowodach debata publiczna w Polsce i Europie, którego wyniki ujrzały dziś światło dzienne. W raporcie Kto (naprawdę) Cię namierzył? Facebook w polskiej kampanii wyborczej jego autorzy dzielą się wnioskami z analizy marketingu politycznego w sieci i wykorzystywania profili psychometrycznych internautów do zarządzania ubiegłorocznymi kampaniami wyborczymi – podczas majowego wyścigu po mandaty europejskiego oraz październikowego – po fotele Sejmie i Senacie.


 Pod lupę wzięto reklamy, które pojawiały się na platformie stworzonej przez Zuckerberga, a ich wiwisekcję przeprowadzono z pomocą ponad 6 tys. polskich użytkowników. Tych ostatnich poproszono o zainstalowanie na swoich urządzeniach specjalnej wtyczki do przeglądarki Kto Cię namierzył. Ponadto badacze korzystali z informacji uzyskanych bezpośrednio od Facebooka, jego biblioteki reklam oraz przez interfejs programistyczny aplikacji (API). „Facebook wie o Tobie więcej, niż myślisz – co lubisz, czego się boisz, czy masz depresję, czy Twój związek przechodzi kryzys. Zna też Twoje poglądy polityczne. W rękach osób chcących wpływać na wybory ta wiedza to potężna broń. Pozwala grać na emocjach wyborców, dezinformować, wyławiać niezdecydowanych i agitować. O szczegółach tych praktyk ciągle niewiele wiadomo” – pisali autorzy projektu. O tym, czy udało im się zmienić stan owej wiedzy rozmawiamy z prawniczką i przedstawicielką Fundacji Panoptykon, Karoliną Iwańską.

***
Paulina Januszewska: Jaka była teza i cel waszych badań?

Karolina Iwańska: Badanie było inspirowane skandalem Cambridge Analytica (CA) z 2018 roku, kiedy dowiedzieliśmy się, że do targetowania reklam politycznych w Wielkiej Brytanii i USA były wykorzystywane informacje o profilu psychometrycznym użytkowników wiodących platform internetowych. Komunikaty widoczne m.in. na Facebooku były bardzo szczegółowo dopasowane do poszczególnych grup odbiorców i wykorzystywały wrażliwe dane, nawet takie, jak profil osobowości czy zdrowie psychiczne.

Gdy narracja dotycząca CA zaczęła karmić unijną dyskusję na temat dezinformacji i manipulacji wyborcami, w Europie zakiełkowały inicjatywy mające na celu zwiększenie przejrzystości reklam politycznych i badające odpowiedzialność różnych aktorów marketingu politycznego w sieci – głównie platform i partii, ale też pośredników takich jak CA – za to, co trafia do potencjalnego wyborcy.
W 2018 roku Unia Europejska opublikowała kodeks dobrych praktyk przeciwko dezinformacji w sieci, do którego przystąpili cyfrowi giganci, w tym Facebook i Google, zobowiązując się do zwiększenia przejrzystości targetowania i finansowania reklam politycznych. Efektem kodeksu było m.in. udostępnienie przez Facebooka w Europie Biblioteki reklam, która gromadzi wszystkie reklamy zdefiniowane przez platformę jako polityczne. Dostępność tych narzędzi pozwoliła nam bliżej przyjrzeć się, jak narzędzia reklamowe Facebooka są wykorzystywane przez polskie partie polityczne.

Co nam daje ta wiedza, skoro i bez badań można łatwo stwierdzić, że marketing polityczny w naszym kraju raczej nie dorównuje temu, co dzieje się na Wyspach lub za oceanem?

Zdawaliśmy sobie sprawę, że nasz system polityczny zdecydowanie różni się od tych państw, bo polskie partie dysponują mniejszym budżetem, a ochrona danych osobowych jest nad Wisłą — w porównaniu choćby do sytuacji w Stanach — znacznie większa. Ponieważ jednak Unia Europejska zaangażowała się w odpowiedź na problemy związane z reklamą polityczną w sieci, uznaliśmy, że warto rzucić trochę więcej światła na to, jak sytuacja wygląda w przeciętnym europejskim kraju i w ten sposób zasilić debatę konkretnymi obserwacjami.

Kierowała nami zarówno ciekawość, jak też świadomość, że rola platform internetowych w kształtowaniu dyskursu politycznego rośnie. Przed tym badaniem w Fundacji Panoptykon przyglądaliśmy się bańkom informacyjnym na Twitterze, obserwując, jak porozumiewamy się na tej platformie, a także – czy sposób jej zaprojektowania sprzyja wymianie poglądów. Przeważającą część materiałów stanowiły reklamy wizerunkowe, czyli zdjęcie kandydata opatrzone hasłem wyborczym partii i zachętą do głosowania. Ewentualnie były to informacje o stanowiskach, podkreślające, jaką funkcję pełni w tej chwili dana osoba. Zaskakująco niewielką część – zaledwie 37 proc. wszystkich treści – stanowiły reklamy dotyczące konkretnych tematów, spraw społecznych czy propozycji programów wyborczych. Do takich konkretnych kwestii, jak np. ochrona zdrowia czy klimat, dużo częściej odwoływano się wprost, w materiałach organicznych, niesponsorowanych.

Nie brakowało też przypadków tzw. kampanii negatywnej, czyli treści krytykujących propozycje kontrkandydatów lub konkretne osoby, związane z przeciwnikami politycznymi. Przykładem mogą być facebookowe banery Lewicy, która krytykowała politykę węglową PiS, a także ministra Sprawiedliwości, Zbigniewa Ziobrę, za reformę sądowniczą.

Niektóre z reklam operowały ostrzejszym językiem, przez co ocierały się o mowę nienawiści. W raporcie pokazujemy materiał przygotowany przez kandydatów partii rządzącej, zawierający hasła wrogie środowiskom osób LGBT i oponentom z Lewicy i KO, określanym jako przeciwnicy „tradycyjnego, chrześcijańskiego modelu rodziny”. Mowa nienawiści pojawiała się jednak głównie w treściach niesponsorowanych. Choć Facebook jest związany tym, co zleci mu reklamodawca, to jego rola — w zakresie profilowania odbiorców reklam i optymalizacji kampanii — powinna być poddana większej kontroli społecznej.

Taką konieczność dostrzega Unia Europejska, zwłaszcza że rola Facebooka i innych platform w życiu społecznym rośnie.  Dobrze widzimy to w czasach pandemii, gdy okazuje się, że chcąc porozumiewać się z bliskimi i śledzić informacje z kraju i świata, w coraz większym stopniu jesteśmy zależni od dominujących platform.  Po pandemii czeka nas poważna rozmowa o tym, w jaki sposób ograniczyć tę władzę i poddać ją społecznej kontroli.

W Brukseli będzie się ona toczyć w kontekście Kodeksu Usług Cyfrowych (Digital Services Act), nad którym już ruszyły prace. Szczególnie ważne będzie uregulowanie tego, co platformy mają pokazywać użytkownikom i badaczom. Obecnie dostępne narzędzia to nadal to za mało, by uzyskać wiarygodne informacje.Dlaczego?

Zarówno Biblioteka reklam, jak i dostępna dla użytkowników informacja „Dlaczego widzę tę reklamę?”, nie pozwalają – ani badaczom, ani użytkownikom – zweryfikować, do kogo chciał dotrzeć reklamodawca i jak ten proces zoptymalizował Facebook. Nasze obserwacje, potwierdzają, że „Dlaczego to widzę” zawiera zbyt ogólne informacje o kryteriach targetowania. Czasami wręcz wprowadzają one w błąd, ponieważ pokazują tylko jedno kryterium (dość ogólne i najbardziej popularne), podczas gdy reklamodawca mógł wybrać ich wiele.